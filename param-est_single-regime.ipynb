{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COMFORT Model parameter estimation (single regime case).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOBw3603rvLGrYRfoPiWk2E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6d5Ru4MLdTw8","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import scipy.stats as sc\n","import scipy.optimize as optim\n","import scipy.linalg as sclinalg\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJeI0mdvje1t","colab_type":"code","colab":{}},"source":["def create_G(dist,lda,xi,psi,T):\n","  #This function creates G_t with the desired distribution and sample sizes\n","  sample_size = int(T)\n","\n","  if (dist == \"MALap\"):\n","    G_dist = sc.laplace(scale=lda)\n","    G = G_dist.rvs(size=sample_size)\n","  elif (dist == \"NIG\"):\n","    G_dist = sc.geninvgauss(p=lda, b=np.sqrt(xi*psi), scale=np.sqrt(xi/psi))\n","    G = G_dist.rvs(size=sample_size)\n","  elif (dist == \"MAt\"):\n","    G_dist = sc.t(df=xi)\n","    G = G_dist.rvs(size=sample_size)\n","\n","  return G"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xENxzPT6jTN9","colab_type":"code","colab":{}},"source":["def create_S(omega,alpha,beta,mu,gamma,T,K,y,G):\n","  #This function creates the matrix for S_t, which is governed by the garch(1,1) alike dynamics\n","\n","  omega_tmp = omega.reshape(K,1)\n","  alpha_tmp = alpha.reshape(K,1)\n","  beta_tmp = beta.reshape(K,1)\n","  mu_tmp = mu.reshape(K,1)\n","  gamma_tmp = gamma.reshape(K,1)\n","\n","  S_matrix = np.zeros([T+1,K,K])\n","  S_2 = np.divide(omega_tmp,1 - alpha_tmp - beta_tmp).reshape(K,1)\n","  S_matrix[0,:,:] = np.diag(np.sqrt(S_2).reshape(1,K).squeeze())\n","\n","  for t in range(1,T+1):\n","    S_tmp = np.diag(S_matrix[t-1,:,:]).reshape(K,1)\n","    epsilon = y[:,t-1].reshape(K,1) - mu_tmp - gamma_tmp*G[t-1]\n","    S_2 = omega_tmp + np.multiply(alpha_tmp,np.square(epsilon)) + np.multiply(beta_tmp,np.square(S_tmp))\n","\n","    #Checking purpose#\n","    if (S_2.any() < 0):\n","      print(\"Error!!! something wrong with omega,alpha,beta\") #Checking purpose#\n","\n","    S_matrix[t,:,:] = np.diag(np.sqrt(S_2).reshape(1,K).squeeze())\n","\n","  return S_matrix[1:(T+1),:,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6zQwuQZdn7t","colab_type":"code","colab":{}},"source":["def log_likelihood_mean_vol(omega,alpha,beta,mu,gamma,T,K,y,G):\n","  #This function calculates the mean_vol part of the log-likelihood\n","\n","  mu_tmp = mu.reshape(K,1)\n","  gamma_tmp = gamma.reshape(K,1)\n","  S = create_S(omega,alpha,beta,mu,gamma,T,K,y,G)\n","  \n","  sum = 0\n","  for t in range(T):\n","    term_1 = K*np.log(2*math.pi)\n","\n","    term_2 = np.log(np.square(np.linalg.det(S[t,:,:])))\n","\n","    epsilon = y[:,t].reshape(K,1) - mu_tmp - gamma_tmp*G[t]\n","    S_inv_2 = np.dot(np.linalg.pinv(S[t,:,:]),np.linalg.pinv(S[t,:,:]))\n","    term_3 = np.power(G[t],-1) * np.dot(np.dot(epsilon.T,S_inv_2),epsilon)\n","\n","    #iter_sum = term_1 + term_2 + term_3 + np.log(np.power(G[t],K))\n","    iter_sum = term_1 + term_2 + term_3\n","    sum += iter_sum.item()\n","  \n","  return -0.5*sum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YLunYkfldoC6","colab_type":"code","colab":{}},"source":["def log_likelihood_Corr(omega,alpha,beta,mu,gamma,Corr,T,K,y,G):\n","  #This function calculates the Corr part of the log-likelihood\n","\n","  mu_tmp = mu.reshape(K,1)\n","  gamma_tmp = gamma.reshape(K,1)\n","  S = create_S(omega,alpha,beta,mu,gamma,T,K,y,G)\n","  \n","  sum = 0\n","  for t in range(T):\n","    epsilon = y[:,t].reshape(K,1) - mu_tmp - gamma_tmp*G[t]\n","    e_t = np.power(G[t],-0.5) * np.dot(np.linalg.pinv(S[t,:,:]),epsilon)\n","\n","    term_1 = np.log(np.absolute(np.linalg.det(Corr)))\n","    term_2 = np.dot(np.dot(e_t.T,np.linalg.pinv(Corr)),e_t)\n","    term_3 = np.dot(e_t.T,e_t)\n","\n","    iter_sum = term_1 + term_2 + term_3\n","    sum += iter_sum.item()\n","  \n","  return -0.5*sum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNEPlFCzdoJZ","colab_type":"code","colab":{}},"source":["def log_likelihood_G(dist,lda,xi,psi,G):\n","  #This function calculates the log-likelihood of G_t\n","\n","  if (dist == \"MALap\"):\n","    G_dist = sc.laplace(scale=lda)\n","  elif (dist == \"NIG\"):\n","    G_dist = sc.geninvgauss(p=lda, b=np.sqrt(xi*psi), scale=np.sqrt(xi/psi))\n","  elif (dist == \"MAt\"):\n","    G_dist = sc.t(df=xi)\n","\n","  sum = 0\n","  for t in range(len(G)):\n","    sum += G_dist.logpdf(G[t]).item()\n","  \n","  return -0.5*sum  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mF0sofzjKw8","colab":{}},"source":["def log_likelihood_complete(omega,alpha,beta,mu,gamma,Corr,dist,lda,xi,psi,T,K,y,G):\n","  #This function calculates the complete log-likelihood\n","\n","  return log_likelihood_mean_vol(omega,alpha,beta,mu,gamma,T,K,y,G) + log_likelihood_Corr(omega,alpha,beta,mu,gamma,Corr,T,K,y,G) + log_likelihood_G(dist,lda,xi,psi,G)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3j4ANJzkRhv","colab_type":"code","colab":{}},"source":["def CM_1_P_para_reshape(omega,alpha,beta,mu,gamma,vec,k):\n","  #This function updates a row of values for all 5 parameter vectors that belong to the set Theta_P\n","\n","  vec = vec.reshape(5,)\n","  omega_tmp = omega\n","  alpha_tmp = alpha\n","  beta_tmp = beta\n","  mu_tmp = mu\n","  gamma_tmp = gamma\n","\n","  omega_tmp[k] = vec[0]\n","  alpha_tmp[k] = vec[1]\n","  beta_tmp[k] = vec[2]\n","  mu_tmp[k] = vec[3]\n","  gamma_tmp[k] = vec[4]\n","  return omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsZQLKTbN3RT","colab_type":"code","colab":{}},"source":["def flatten_Corr(Corr):\n","  #This function flattens the upper-triangular Correlation matrix, so the resulting vector could be passed to the optimization algo\n","\n","  vec = []\n","  N = Corr.shape[0]\n","  for i in range(N-1):\n","    for j in range(i+1,N):\n","      vec.append(Corr[i,j])\n","  return vec\n","\n","def CM_1_C_para_reshape(vec):\n","  #This function updates the Correlation matrix (set Theta_C)\n","\n","  size = int(0.5 * (1 + np.sqrt(1 + 8*len(vec))))\n","  Corr_new = np.eye(size,size)\n","  \n","  tmp = 0\n","  for i in range(size-1):\n","    for j in range(i+1,size):\n","      Corr_new[i,j] = vec[tmp]\n","      tmp += 1\n","\n","  i_lower = np.tril_indices(size, -1)\n","  Corr_new[i_lower] = Corr_new.T[i_lower]\n","  return Corr_new"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfrP9sF8TPul","colab_type":"code","colab":{}},"source":["def imputed_G(omega,alpha,beta,mu,gamma,Corr,dist,lda,xi,psi,T,K,y):\n","  #This function creates the imputed G_t for the EM algo\n","\n","  #Calculate the matrix for s using the current set of parameters first\n","  G_old = create_G(dist,lda,xi,psi,T)\n","  S = create_S(omega,alpha,beta,mu,gamma,T,K,y,G_old)\n","  mu_tmp = mu.reshape(K,1)\n","  G_new = np.zeros([T,])\n","\n","  #Set the Theta_D set for the imputed g\n","  if (dist == \"MALap\"):\n","    lda_new = np.maximum(lda - 0.5*K,10e-10)\n","    lda_new = lda_new.item()\n","    G_new = create_G(dist,lda_new,xi,psi,T)\n","  elif (dist == \"NIG\"):\n","    for t in range(T):\n","      H_t_inv = np.linalg.pinv(np.dot(np.dot(S[t,:,:],Corr),S[t,:,:]))\n","      adjust_term = np.dot(np.dot((y[:,t].reshape(K,1) - mu_tmp).T,H_t_inv),(y[:,t].reshape(K,1) - mu_tmp))\n","      xi_new = xi + adjust_term\n","      xi_new = xi_new.item()\n","      G_new[t] = create_G(dist,lda,xi_new,psi,1)\n","  elif (dist == \"MAt\"):\n","    lda_new = lda - 0.5*K\n","    lda_new = lda_new.item()\n","    for t in range(T):\n","      H_t_inv = np.linalg.pinv(np.dot(np.dot(S[t,:,:],Corr),S[t,:,:]))\n","      adjust_term = np.dot(np.dot((y[:,t].reshape(K,1) - mu_tmp).T,H_t_inv),(y[:,t].reshape(K,1) - mu_tmp))\n","      xi_new = xi + adjust_term\n","      xi_new = xi_new.item()\n","      G_new[t] = create_G(dist,lda_new,xi_new,psi,1)\n","  \n","  return G_new"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2M4pMT-jewE","colab_type":"code","colab":{}},"source":["def EM_algo(omega,alpha,beta,mu,gamma,Corr,dist,lda,xi,psi,T,K,y,iteration,optim_method,tolerance):\n","  #Main EM algorithm to estimate all parameters (Theta_P,Theta_C,Theta_D)\n","  diff = 1000\n","  current_it = 0\n","  E = []\n","\n","  omega_tmp = omega\n","  alpha_tmp = alpha\n","  beta_tmp = beta\n","  mu_tmp = mu\n","  gamma_tmp = gamma\n","  Corr_tmp = Corr\n","  lda_tmp = lda\n","  xi_tmp = xi\n","  psi_tmp = psi\n","\n","  while (current_it < iteration) and (diff > tolerance):\n","    current_it += 1 #Keep track of the current iteration of EM algo\n","\n","    ######E-step#####\n","  \n","    ##Calculate the imputed g\n","    G_hat = imputed_G(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,dist,lda_tmp,xi_tmp,psi_tmp,T,K,y)\n","    print(\"G_hat done\\n {}\\n\".format(G_hat))\n","\n","    ##Calculate the expected value of complete log-likelihood\n","    E_mean_vol = log_likelihood_mean_vol(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,T,K,y,G_hat)\n","    E_Corr = log_likelihood_Corr(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,T,K,y,G_hat)\n","    E_G = log_likelihood_G(dist,lda_tmp,xi_tmp,psi_tmp,G_hat)\n","    E_complete_log_lld = E_mean_vol + E_Corr + E_G\n","    E.append(E_complete_log_lld)\n","    \n","    print(\"E-step done\")\n","    print(E_complete_log_lld)#Checking purpose\n","\n","    ######M-step#####\n","\n","    ##CM1 (P) Updating Theta_P set\n","\n","    #We individually estimate the Theta_P set for each asset\n","    for k in range(K):\n","      #First we create a lambda function to facilitate the optimization algo\n","      #The only input will be the parameter vector that we need to estimate\n","      CM_1_P_para_reshape_k = lambda vec: CM_1_P_para_reshape(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,vec,k)\n","\n","      #Redefine the function that calculates the mean-vol part of the log-likelihood, so it only accepts a single vector as input\n","      def CM_1_P_func(x): \n","        omega_new,alpha_new,beta_new,mu_new,gamma_new = CM_1_P_para_reshape_k(x)\n","        return -log_likelihood_mean_vol(omega_new,alpha_new,beta_new,mu_new,gamma_new,T,K,y,G_hat)\n","\n","      #Initial value for the parameters (which is set as the value at last iteration)\n","      CM_1_P_init = np.array([omega_tmp[k], alpha_tmp[k], beta_tmp[k], mu_tmp[k], gamma_tmp[k]])\n","      \n","      #set bounds of the parameters\n","      bnds = ((10e-7, None), (10e-7, None),(10e-7, None),(None, None),(None, None))\n","      \n","      #Conduct Minimization\n","      CM_1_P = optim.minimize(fun=CM_1_P_func,x0=CM_1_P_init, method=optim_method, bounds=bnds)\n","      omega_tmp[k],alpha_tmp[k],beta_tmp[k],mu_tmp[k],gamma_tmp[k] = CM_1_P.x\n","      print(\"CM1(P)-step {} done\".format(k+1))\n","\n","    print(\"CM1(P)-step all done\")\n","    #print(np.array([omega,alpha,beta,mu,gamma])) #Checking purpose\n","\n","\n","    ##CM1 (C) Updating Theta_C set\n","\n","    #Redefine the function that calculates the Corr part of log-likelihood, so it only accepts a single vector as input\n","    def CM_1_C_func(x):\n","      Corr_new = CM_1_C_para_reshape(x)\n","      return -log_likelihood_Corr(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_new,T,K,y,G_hat)\n","\n","    #Initial value for the optimization, done by flattening the upper-triangular Correlation matrix\n","    CM_1_C_init = flatten_Corr(Corr_tmp)\n","    \n","    #Set bounds for all values in the upper-triangular Correlation matrix\n","    bnds = []\n","    for i in range(len(CM_1_C_init)):\n","      bnds.append((-1,1))\n","\n","    #Confuct Minimization\n","    CM_1_C = optim.minimize(fun=CM_1_C_func,x0=CM_1_C_init, method=optim_method,bounds=bnds)\n","    Corr_tmp = CM_1_C_para_reshape(CM_1_C.x)\n","    \n","    print(\"CM1(C)-step done\")\n","    print(Corr_tmp) #Checking purpose\n","\n","    \n","    ##CM2 Updating Theta_D set\n","    #For each distribution, the optimization parameter will be different, so we seperate into 3 cases\n","\n","    if (dist == \"MALap\"):\n","      #Redefine the function that calculates the complete log-likelihood, so it only accepts a single number as input\n","      def CM_2_func_MALap(x):\n","        E_mean_vol = log_likelihood_mean_vol(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,T,K,y,G_hat)\n","        E_Corr = log_likelihood_Corr(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,T,K,y,G_hat)\n","        E_G = log_likelihood_G(dist,x,xi_tmp,psi_tmp,G_hat)\n","        return E_mean_vol + E_Corr + E_G\n","\n","      #Set bounds for parameter\n","      bnds = ((10e-10,None),)\n","\n","      #Conduct Minimization\n","      CM_2 = optim.minimize(fun=CM_2_func_MALap, x0=lda_tmp, method=optim_method, bounds=bnds)\n","      lda_tmp = CM_2.x\n","\n","    elif (dist == \"NIG\"):\n","      #Redefine the function that calculates the complete log-likelihood, so it only accepts a single number as input\n","      def CM_2_func_NIG(x):\n","        E_mean_vol = log_likelihood_mean_vol(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,T,K,y,G_hat)\n","        E_Corr = log_likelihood_Corr(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,T,K,y,G_hat)\n","        E_G = log_likelihood_G(dist,lda_tmp,x,psi_tmp,G_hat)\n","        return E_mean_vol + E_Corr + E_G         \n","        \n","      #Set bounds for parameter\n","      bnds = ((10e-10,10),)\n","\n","      #Conduct Minimization\n","      CM_2 = optim.minimize(fun=CM_2_func_NIG,x0=xi_tmp, method=optim_method, bounds=bnds)\n","      xi_tmp = (CM_2.x).item()\n","\n","    elif (dist == \"MAt\"):\n","      #Redefine the function that calculates the complete log-likelihood, so it only accepts a single number as input\n","      def CM_2_func_MAt(x):\n","        E_mean_vol = log_likelihood_mean_vol(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,T,K,y,G_hat)\n","        E_Corr = log_likelihood_Corr(omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,T,K,y,G_hat)\n","        E_G = log_likelihood_G(dist,lda_tmp,x,psi_tmp,G_hat)\n","        return E_mean_vol + E_Corr + E_G         \n","        \n","      #Set bounds for parameter\n","      bnds = ((10e-10,None),)\n","\n","      #Conduct Minimization\n","      CM_2 = optim.minimize(fun=CM_2_func_MAt,x0=xi_tmp, method=optim_method)\n","      xi_tmp = CM_2.x\n","      lda_tmp = -0.5*xi_tmp\n","    \n","    print(\"CM2-step done\")\n","    print(np.array([lda_tmp,xi_tmp,psi_tmp])) #Checking purpose\n","\n","    if (current_it > 1):\n","      diff = abs(E[current_it-1] - E[current_it-2])\n","      print(\"diff in iteration {a} is {b}\".format(a=current_it,b=diff))\n","    \n","    print(\"Iteration {} completed\".format(current_it))\n","\n","  return omega_tmp,alpha_tmp,beta_tmp,mu_tmp,gamma_tmp,Corr_tmp,lda_tmp,xi_tmp,psi_tmp,E"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESYS6w3apDxr","colab_type":"code","colab":{}},"source":["def create_y(omega,alpha,beta,mu,gamma,Corr,T,K,G,Z):\n","  #This function creates simulated return y for checking purpose\n","\n","  omega_tmp = omega.reshape(K,1)\n","  alpha_tmp = alpha.reshape(K,1)\n","  beta_tmp = beta.reshape(K,1)\n","  mu_tmp = mu.reshape(K,1)\n","  gamma_tmp = gamma.reshape(K,1)\n","\n","  y = np.zeros([K,T])\n","  #S_2 = np.divide(omega_tmp,1 - alpha_tmp - beta_tmp).reshape(K,1)\n","  S_2 = np.zeros([K,1])\n","  epsilon = np.zeros([K,1])\n","\n","  for t in range(T):\n","    print(\"iteration {}\\n\".format(t+1))\n","\n","    S_2 = omega_tmp + np.multiply(alpha_tmp,np.square(epsilon)) + np.multiply(beta_tmp,S_2)\n","    print(\"S_2 is\\n {}\\n\".format(S_2))\n","\n","    #Checking purpose#\n","    if (S_2.any() < 0):\n","      print(\"Error!!! something wrong with omega,alpha,beta\") #Checking purpose#\n","\n","    S_reshape = np.diag(np.sqrt(S_2).reshape(1,K).squeeze())\n","\n","    H_t = np.dot(np.dot(S_reshape,Corr),S_reshape)\n","    print(\"H_t is\\n {}\\n\".format(H_t))\n","\n","    H_t_sqrt = sclinalg.sqrtm(H_t)\n","    print(\"H_t_0.5 is\\n {}\\n\".format(H_t_sqrt))\n","\n","    Z = sc.norm.rvs(size=K)\n","    print(\"Z is\\n {}\\n\".format(Z))\n","\n","    if (G[t] < 0):\n","      print(\"Something wrong with G\\n\")\n","      print(\"G is {}\\n\".format(G[t]))\n","    else:\n","      G_sqrt = np.sqrt(G[t])\n","      print(\"sqrt G is {}\\n\".format(G_sqrt))\n","\n","    epsilon = (G_sqrt * np.dot(H_t_sqrt,Z)).reshape(K,1)\n","    print(\"epsilon is\\n {}\\n\".format(epsilon))\n","    \n","    y[:,t] = (mu_tmp + G[t] * gamma_tmp + epsilon).reshape(K,)\n","    print(\"result is\\n {}\\n\".format(mu_tmp + G[t] * gamma_tmp + epsilon))\n","\n","  return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpBXUsmoje0W","colab_type":"code","colab":{}},"source":["##Simulate test data##\n","\n","#Set random seed\n","np.random.seed(1234)\n","\n","#Initialization of parameters sets#\n","T_test = 100\n","K_test = 5\n","\n","#Theta_P set\n","omega_test = np.array([8e-6,2e-6,4e-6,6e-6,8e-6])\n","alpha_test = np.array([0.04,0.03,0.02,0.03,0.04])\n","beta_test = np.array([0.7,0.08,0.75,0.8,0.7])\n","mu_test = np.array([-0.00005,-0.000002,0.000001,0.000003,0.000005])\n","gamma_test =  np.array([0.001,-0.002,0.003,-0.004,0.005])\n","\n","#Theta_C set\n","Corr_test = np.array([[1.00,-0.10,0.12,-0.14,0.16],\n","                 [-0.10,1.00,0.18,-0.20,0.22],\n","                 [0.12,0.18,1.00,0.24,-0.26],\n","                 [-0.14,-0.20,0.24,1.00,0.28],\n","                 [0.16,0.22,-0.26,0.28,1.00]])\n","\n","#Theta_D set\n","dist_test = \"NIG\" #Choose between \"MALap\" , \"NIG\" , \"MAt\"\n","\n","if (dist_test == \"MALap\"):\n","  G_lda_test = 4.25\n","  G_xi_test = 10e-10\n","  G_psi_test = 2 \n","elif (dist_test == \"NIG\"):\n","  G_lda_test = -0.5 \n","  G_xi_test = 4.25\n","  G_psi_test = 1 \n","elif (dist_test == \"MAt\"):\n","  G_xi_test = 4.25\n","  G_lda_test = -0.5 * G_xi_test\n","  G_psi_test = 10e-10\n","\n","#Simulated returns\n","G_test = create_G(dist_test,G_lda_test,G_xi_test,G_psi_test,T_test)\n","Z_test = sc.norm.rvs(size=T_test*K_test).reshape(K_test,T_test)\n","y_test = create_y(omega_test,alpha_test,beta_test,mu_test,gamma_test,Corr_test,T_test,K_test,G_test,Z_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJbUdNCttVdC","colab_type":"code","colab":{}},"source":["##Parameter estimation by simulated data##\n","\n","#Set random seed\n","np.random.seed(9999)\n","\n","#Initialization of parameters sets#\n","T = 100\n","K = 5\n","\n","#Theta_P set\n","omega_guess = sc.uniform.rvs(scale = 10e-5, size=K)\n","alpha_guess = sc.uniform.rvs(scale = 0.05, size=K)\n","beta_guess = sc.uniform.rvs(loc=0.5,scale=0.5, size=K)\n","mu_guess = sc.uniform.rvs(scale = 10e-5, size=K)\n","gamma_guess = sc.uniform.rvs(loc=-0.0001,scale=0.0071, size=K)\n","print(\"Initial value for parameter set Theta_P:\\n {}\\n\".format(np.array([omega_guess,alpha_guess,beta_guess,mu_guess,gamma_guess])))\n","\n","#Theta_C set\n","Corr_vec = sc.uniform.rvs(loc=-0.2,scale=0.4,size=int(0.5*K*(K-1)))\n","Corr_guess = CM_1_C_para_reshape(Corr_vec)\n","print(\"Initial value for parameter set Theta_C:\\n {}\\n\".format(Corr_guess))\n","\n","#Theta_D set\n","dist = \"NIG\" #Choose between \"MALap\" , \"NIG\" , \"MAt\"\n","\n","if (dist == \"MALap\"):\n","  G_lda_guess = sc.uniform.rvs(loc=1,scale=1,size=1)\n","  G_xi_guess = 10e-10\n","  G_psi_guess = 2 \n","  print(\"Initial value for parameter set Theta_D:\\n {}\\n\".format(np.array([G_lda_guess.item(),G_xi_guess,G_psi_guess])))\n","elif (dist == \"NIG\"):\n","  G_lda_guess = -0.5 \n","  G_xi_guess =  sc.uniform.rvs(loc=1,scale=1,size=1)\n","  G_psi_guess = 1 \n","  print(\"Initial value for parameter set Theta_D:\\n {}\\n\".format(np.array([G_lda_guess,G_xi_guess.item(),G_psi_guess])))\n","elif (dist == \"MAt\"):\n","  G_xi_guess = sc.uniform.rvs(loc=1,scale=1,size=1)\n","  G_lda_guess = -0.5 * G_xi_guess\n","  G_psi_guess = 10e-10\n","  print(\"Initial value for parameter set Theta_D:\\n {}\\n\".format(np.array([G_lda_guess,G_xi_guess,G_psi_guess.item()])))\n","\n","#parameters for EM algo\n","iteration_num = 1000\n","opt_method = 'L-BFGS-B'\n","tol = 10e-5\n","\n","#Parameter estimation\n","omega_final,alpha_final,beta_final,mu_final,gamma_final,Corr_final,G_lda_final,G_xi_final,G_psi_final,_ = EM_algo(omega_guess,alpha_guess,beta_guess,mu_guess,gamma_guess,Corr_guess,dist,G_lda_guess,G_xi_guess,G_psi_guess,T,K,y_test,iteration_num,opt_method,tol)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1T_oacxX3B-","colab_type":"code","colab":{}},"source":["##Read files##\n","\n","import pandas as pd\n","import os\n","\n","all_files = os.listdir()\n","\n","#cnt = 0\n","#for filename in all_files:\n","  #if filename.endswith(\".csv\"):\n","    #cnt += 1\n","\n","close = []\n","\n","cnt = 0\n","for filename in all_files:\n","  if filename.endswith(\".csv\"):\n","    cnt += 1\n","    data = pd.read_csv(filename)\n","    data_close = np.array(data[\"close\"])\n","    close.append(data_close)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhAFundDFC4s","colab_type":"code","colab":{}},"source":["##Parameter estimation by real data##\n","\n","np.random.seed(1357)\n","price = np.array(close).reshape(len(close[0]),len(close))\n","price = price.T\n","returns = np.divide(price[:,1:1259] - price[:,0:1258],price[:,0:1258])\n","\n","T = returns.shape[1]\n","K = returns.shape[0]\n","\n","garch_para = pd.read_csv(\"Estimation_param.csv\")\n","omega_init = np.array(garch_para[\"V1\"])\n","alpha_init = np.array(garch_para[\"V2\"])\n","beta_init = np.array(garch_para[\"V3\"])\n","mu_init = np.array(pd.read_csv(\"Estimation_mu.csv\"))\n","gamma_init = sc.uniform.rvs(loc=-0.0001,scale=0.0071, size=K)\n","\n","Corr_init = np.array(pd.read_csv(\"Estimation_Gam.csv\"))\n","\n","dist = \"NIG\"\n","lda_init = -0.5\n","xi_init = sc.uniform.rvs(loc=1,scale=2,size=1)\n","psi_init = 1\n","\n","#parameters for EM algo\n","iteration_num = 100\n","opt_method = 'L-BFGS-B'\n","tol = 10e-5\n","\n","#Parameter estimation\n","omega_final,alpha_final,beta_final,mu_final,gamma_final,Corr_final,G_lda_final,G_xi_final,G_psi_final,_ = EM_algo(omega_init,alpha_init,beta_init,mu_init,gamma_init,Corr_init,dist,lda_init,xi_init,psi_init,T,K,returns,iteration_num,opt_method,tol)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fz3QnkHh9Y03","colab_type":"code","colab":{}},"source":["#Save parameters into csv\n","\n","np.savetxt(\"omega.csv\", omega_final, delimiter=\",\")\n","np.savetxt(\"alpha.csv\", alpha_final, delimiter=\",\")\n","np.savetxt(\"beta.csv\", beta_final, delimiter=\",\")\n","np.savetxt(\"mu.csv\", mu_final, delimiter=\",\")\n","np.savetxt(\"gamma.csv\", gamma_final, delimiter=\",\")\n","np.savetxt(\"Corr.csv\", Corr_final, delimiter=\",\")\n","np.savetxt(\"G_para.csv\", np.array([G_lda_final,G_xi_final,G_psi_final]), delimiter=\",\")"],"execution_count":0,"outputs":[]}]}